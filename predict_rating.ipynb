{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a predictive model that will tell us if a stand-up comedy special will receive an above or below average IMDb rating\n",
    "\n",
    "1) Train weak learners: Random Forrest, Stochastic Gradient Descent.\n",
    "\n",
    "2) Perform a grid search to find optimal parameters for an XGBoost classifier.\n",
    "\n",
    "3) Put all three models into an ensemble for a final accuracy of 0.76\n",
    "\n",
    "By combining the power of three weaker models into an ensemble, it was possible to predict what the IMDb rating of a comedy special is with decent accuracy. The models would probably be improved by using more training data. The LDA model that produced these topic vectors (in topic_modeling_LDA.ipynb) could also be improved with more training data or perhaps by using different hyperparameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 322 entries, 0 to 329\n",
      "Data columns (total 23 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   title            322 non-null    object \n",
      " 1   date_posted      322 non-null    object \n",
      " 2   link             322 non-null    object \n",
      " 3   name             318 non-null    object \n",
      " 4   year             306 non-null    float64\n",
      " 5   transcript       322 non-null    object \n",
      " 6   language         322 non-null    object \n",
      " 7   runtime          272 non-null    float64\n",
      " 8   rating           272 non-null    float64\n",
      " 9   rating_type      322 non-null    int64  \n",
      " 10  words            322 non-null    object \n",
      " 11  word_count       322 non-null    int64  \n",
      " 12  f_words          322 non-null    int64  \n",
      " 13  s_words          322 non-null    int64  \n",
      " 14  diversity        322 non-null    int64  \n",
      " 15  diversity_ratio  322 non-null    float64\n",
      " 16  police_AA        322 non-null    float64\n",
      " 17  clean            322 non-null    float64\n",
      " 18  UK               322 non-null    float64\n",
      " 19  relationships    322 non-null    float64\n",
      " 20  animals          322 non-null    float64\n",
      " 21  politics         322 non-null    float64\n",
      " 22  big_picture      322 non-null    float64\n",
      "dtypes: float64(11), int64(5), object(7)\n",
      "memory usage: 60.4+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "df = pd.read_pickle('stand-up-data-w-LDA.pkl')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(322, 7)\n",
      "(322,)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(df[['police_AA', 'clean', 'UK', 'relationships', 'animals', 'politics', 'big_picture']])\n",
    "y = np.array(df.rating_type)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and testing sets and train models.\n",
    "\n",
    "- Train Random Forrest model\n",
    "\n",
    "- Train SGD model\n",
    "\n",
    "- Perform grid search and train XGB model\n",
    "\n",
    "- Create and ensemble of three classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data training and testing \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF score: 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "# Random Forrest\n",
    "rf = RandomForestClassifier(n_estimators=1001).fit(X_train, y_train)\n",
    "print(f'RF score: {rf.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD score: 0.7346938775510204\n"
     ]
    }
   ],
   "source": [
    "# SGD\n",
    "sgd = linear_model.SGDClassifier().fit(X_train, y_train)\n",
    "print(f'SGD score: {sgd.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.4 s, sys: 491 ms, total: 18.9 s\n",
      "Wall time: 1min 59s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estim...\n",
       "                                     subsample=None, tree_method=None,\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             iid='deprecated', n_jobs=4,\n",
       "             param_grid={'colsample_bytree': [0.3, 0.4, 0.5, 0.7],\n",
       "                         'eta': [0.05, 0.1, 0.15, 0.2, 0.25, 0.3],\n",
       "                         'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "                         'max_depth': [3, 4, 5, 6, 8, 10, 12, 15],\n",
       "                         'min_child_weight': [1, 3, 5, 7]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_log_loss', verbose=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "xgb = XGBClassifier()\n",
    "parameters = {\n",
    "     \"eta\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n",
    "     \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
    "     \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
    "     \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    "     \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ]\n",
    "     }\n",
    "\n",
    "grid = GridSearchCV(xgb,\n",
    "                    parameters, n_jobs=4,\n",
    "                    scoring=\"neg_log_loss\",\n",
    "                    cv=3)\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'colsample_bytree': 0.3, 'eta': 0.05, 'gamma': 0.4, 'max_depth': 3, 'min_child_weight': 1}\n",
      "Best XGB score: 0.6938775510204082\n"
     ]
    }
   ],
   "source": [
    "best_xgb = grid.best_estimator_.fit(X_train, y_train)\n",
    "print(f'Best params: {grid.best_params_}')\n",
    "print(f'Best XGB score: {best_xgb.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier, Ensemble Acc: 0.7551020408163265\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Ensemble\n",
    "estimators = [('rf', rf), ('sgd', sgd), ('xgb', best_xgb)]\n",
    "\n",
    "ensemble = VotingClassifier(estimators, voting='hard')\n",
    "ensemble.fit(X_train, y_train)\n",
    "print('Voting Classifier, Ensemble Acc: {}'.format(ensemble.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the ensemble model for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save ensemble model\n",
    "pickle.dump(ensemble, open('rating_prediction_ens_model.pkl', 'wb'))\n",
    "\n",
    "# # Load ensemble model\n",
    "# with open('rating_prediction_ens_model.pkl','rb') as f:\n",
    "#     ensemble = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
