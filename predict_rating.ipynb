{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a predictive model that will tell us if a stand-up comedy special will receive an above or below average IMDb rating\n",
    "\n",
    "1) Train weak learners: Random Forrest, Stochastic Gradient Descent.\n",
    "\n",
    "2) Perform a grid search to find optimal parameters for an XGBoost classifier.\n",
    "\n",
    "3) Put all three models into an ensemble for a final accuracy of 0.76\n",
    "\n",
    "By combining the power of three weaker models into an ensemble, it was possible to predict what the IMDb rating of a comedy special is with decent accuracy. The models would probably be improved by using more training data. The LDA model that produced these topic vectors (in topic_modeling_LDA.ipynb) could also be improved with more training data or perhaps by using different hyperparameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 322 entries, 0 to 329\n",
      "Data columns (total 25 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   title            322 non-null    object \n",
      " 1   date_posted      322 non-null    object \n",
      " 2   link             322 non-null    object \n",
      " 3   name             318 non-null    object \n",
      " 4   year             306 non-null    float64\n",
      " 5   transcript       322 non-null    object \n",
      " 6   language         322 non-null    object \n",
      " 7   runtime          272 non-null    float64\n",
      " 8   rating           272 non-null    float64\n",
      " 9   rating_type      322 non-null    int64  \n",
      " 10  words            322 non-null    object \n",
      " 11  word_count       322 non-null    int64  \n",
      " 12  f_words          322 non-null    int64  \n",
      " 13  s_words          322 non-null    int64  \n",
      " 14  diversity        322 non-null    int64  \n",
      " 15  diversity_ratio  322 non-null    float64\n",
      " 16  police_AA        322 non-null    float64\n",
      " 17  clean            322 non-null    float64\n",
      " 18  UK               322 non-null    float64\n",
      " 19  relationships    322 non-null    float64\n",
      " 20  animals          322 non-null    float64\n",
      " 21  politics         322 non-null    float64\n",
      " 22  big_picture      322 non-null    float64\n",
      " 23  cluster_LDA      322 non-null    int32  \n",
      " 24  cluster_tfidf    322 non-null    int32  \n",
      "dtypes: float64(11), int32(2), int64(5), object(7)\n",
      "memory usage: 62.9+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from xgboost import XGBClassifier\n",
    "import pickle\n",
    "\n",
    "df = pd.read_pickle('data/stand-up-data-w-clusters.pkl')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create one-hot features for cluster assignments and merge with dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_LDA</th>\n",
       "      <th>1_LDA</th>\n",
       "      <th>2_LDA</th>\n",
       "      <th>3_LDA</th>\n",
       "      <th>4_LDA</th>\n",
       "      <th>5_LDA</th>\n",
       "      <th>6_LDA</th>\n",
       "      <th>0_tfidf</th>\n",
       "      <th>1_tfidf</th>\n",
       "      <th>2_tfidf</th>\n",
       "      <th>3_tfidf</th>\n",
       "      <th>4_tfidf</th>\n",
       "      <th>5_tfidf</th>\n",
       "      <th>6_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0_LDA  1_LDA  2_LDA  3_LDA  4_LDA  5_LDA  6_LDA  0_tfidf  1_tfidf  2_tfidf  \\\n",
       "0      1      0      0      0      0      0      0        0        0        1   \n",
       "1      1      0      0      0      0      0      0        0        0        0   \n",
       "2      1      0      0      0      0      0      0        0        0        0   \n",
       "3      0      1      0      0      0      0      0        0        0        0   \n",
       "4      0      1      0      0      0      0      0        0        0        0   \n",
       "\n",
       "   3_tfidf  4_tfidf  5_tfidf  6_tfidf  \n",
       "0        0        0        0        0  \n",
       "1        0        0        1        0  \n",
       "2        0        1        0        0  \n",
       "3        1        0        0        0  \n",
       "4        1        0        0        0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_LDA_dummies = pd.get_dummies(df['cluster_LDA'])\n",
    "LDA_columns = [str(column) + '_LDA' for column in cluster_LDA_dummies.columns]\n",
    "cluster_LDA_dummies.columns = LDA_columns\n",
    "\n",
    "cluster_tfidf_dummies = pd.get_dummies(df['cluster_tfidf'])\n",
    "tfidf_columns = [str(column) + '_tfidf' for column in cluster_tfidf_dummies.columns]\n",
    "cluster_tfidf_dummies.columns = tfidf_columns\n",
    "\n",
    "cluster_df = pd.merge(cluster_LDA_dummies, cluster_tfidf_dummies, right_index=True, left_index=True)\n",
    "cluster_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'date_posted', 'link', 'name', 'year', 'transcript',\n",
       "       'language', 'runtime', 'rating', 'rating_type', 'words', 'word_count',\n",
       "       'f_words', 's_words', 'diversity', 'diversity_ratio', 'police_AA',\n",
       "       'clean', 'UK', 'relationships', 'animals', 'politics', 'big_picture',\n",
       "       'cluster_LDA', 'cluster_tfidf', '0_LDA', '1_LDA', '2_LDA', '3_LDA',\n",
       "       '4_LDA', '5_LDA', '6_LDA', '0_tfidf', '1_tfidf', '2_tfidf', '3_tfidf',\n",
       "       '4_tfidf', '5_tfidf', '6_tfidf'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(df, cluster_df, right_index=True, left_index=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(272, 7)\n",
      "(272,)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(df[['police_AA', 'clean', 'UK', 'relationships', 'animals', 'politics', 'big_picture']].loc[df.rating > 0])\n",
    "y = np.array(df.rating_type.loc[df.rating > 0])\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and testing sets and train models.\n",
    "\n",
    "- Train Random Forrest model\n",
    "\n",
    "- Train SGD model\n",
    "\n",
    "- Perform grid search and train XGB model\n",
    "\n",
    "- Create and ensemble of three classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data training and testing \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF score: 0.7073170731707317\n"
     ]
    }
   ],
   "source": [
    "# Random Forrest\n",
    "rf = RandomForestClassifier(n_estimators=101).fit(X_train, y_train)\n",
    "print(f'RF score: {rf.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD score: 0.7804878048780488\n"
     ]
    }
   ],
   "source": [
    "# SGD\n",
    "sgd = linear_model.SGDClassifier(loss='modified_huber').fit(X_train, y_train)\n",
    "print(f'SGD score: {sgd.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.1 s, sys: 472 ms, total: 19.6 s\n",
      "Wall time: 1min 33s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estim...\n",
       "                                     subsample=None, tree_method=None,\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             iid='deprecated', n_jobs=4,\n",
       "             param_grid={'colsample_bytree': [0.3, 0.4, 0.5, 0.7],\n",
       "                         'eta': [0.05, 0.1, 0.15, 0.2, 0.25, 0.3],\n",
       "                         'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "                         'max_depth': [3, 4, 5, 6, 8, 10, 12, 15],\n",
       "                         'min_child_weight': [1, 3, 5, 7]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_log_loss', verbose=0)"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "xgb = XGBClassifier()\n",
    "parameters = {\n",
    "     \"eta\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n",
    "     \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
    "     \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
    "     \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    "     \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ]\n",
    "     }\n",
    "\n",
    "grid = GridSearchCV(xgb,\n",
    "                    parameters, n_jobs=4,\n",
    "                    scoring=\"neg_log_loss\",\n",
    "                    cv=3)\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'colsample_bytree': 0.7, 'eta': 0.05, 'gamma': 0.4, 'max_depth': 3, 'min_child_weight': 3}\n",
      "Best XGB score: 0.6097560975609756\n"
     ]
    }
   ],
   "source": [
    "best_xgb = grid.best_estimator_.fit(X_train, y_train)\n",
    "print(f'Best params: {grid.best_params_}')\n",
    "print(f'Best XGB score: {best_xgb.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier, Ensemble Acc: 0.8292682926829268\n"
     ]
    }
   ],
   "source": [
    "# Ensemble\n",
    "estimators = [('rf', rf), ('sgd', sgd), ('xgb', best_xgb)]\n",
    "\n",
    "ensemble = VotingClassifier(estimators, voting='soft')\n",
    "ensemble.fit(X_train, y_train)\n",
    "print('Voting Classifier, Ensemble Acc: {}'.format(ensemble.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The ensemble method performed the best at 0.82 accuracy when taking only the LDA topic probabilities as input. \n",
    "Save the model to a pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save ensemble model\n",
    "# pickle.dump(ensemble, open('models/rating_pred_ens_w_LDAprob_model.pkl', 'wb'))\n",
    "\n",
    "# # Load ensemble model\n",
    "# with open('models/rating_pred_ens_w_LDAprob_model.pkl','rb') as f:\n",
    "#     ensemble = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See what happens when we use cluster assignments only to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(272, 14)\n",
      "(272,)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(df[['0_LDA', '1_LDA', '2_LDA', '3_LDA',\n",
    "       '4_LDA', '5_LDA', '6_LDA', '0_tfidf', '1_tfidf', '2_tfidf', '3_tfidf',\n",
    "       '4_tfidf', '5_tfidf', '6_tfidf']].loc[df.rating > 0])\n",
    "y = np.array(df.rating_type.loc[df.rating > 0])\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data training and testing \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF score: 0.7317073170731707\n"
     ]
    }
   ],
   "source": [
    "# Random Forrest\n",
    "rf = RandomForestClassifier(n_estimators=101).fit(X_train, y_train)\n",
    "print(f'RF score: {rf.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD score: 0.8048780487804879\n"
     ]
    }
   ],
   "source": [
    "# SGD\n",
    "sgd = linear_model.SGDClassifier(loss='modified_huber').fit(X_train, y_train)\n",
    "print(f'SGD score: {sgd.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB score: 0.6341463414634146\n"
     ]
    }
   ],
   "source": [
    "# XGBoosting\n",
    "xgb = XGBClassifier().fit(X_train, y_train)\n",
    "print(f'XGB score: {xgb.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier, Ensemble Acc: 0.7073170731707317\n"
     ]
    }
   ],
   "source": [
    "# Ensemble\n",
    "estimators = [('rf', rf), ('sgd', sgd), ('xgb', xgb)]\n",
    "\n",
    "ensemble = VotingClassifier(estimators, voting='soft')\n",
    "ensemble.fit(X_train, y_train)\n",
    "print('Voting Classifier, Ensemble Acc: {}'.format(ensemble.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD performed the best at 0.80 test accuracy when taking only the cluster assignments as input. \n",
    "Save the model to a pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save sgd model\n",
    "# pickle.dump(sgd, open('models/rating_pred_sgd_w_clusters_model.pkl', 'wb'))\n",
    "\n",
    "# # Load sgd model\n",
    "# with open('models/rating_pred_sgd_w_clusters_model.pkl','rb') as f:\n",
    "#     sgd = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See what happens when we use cluster assignments along with LDA vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(272, 21)\n",
      "(272,)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(df[['police_AA', 'clean', 'UK', 'relationships', 'animals', 'politics', \n",
    "                 'big_picture', '0_LDA', '1_LDA', '2_LDA', '3_LDA',\n",
    "                 '4_LDA', '5_LDA', '6_LDA', '0_tfidf', '1_tfidf', '2_tfidf', '3_tfidf',\n",
    "                 '4_tfidf', '5_tfidf', '6_tfidf']].loc[df.rating > 0])\n",
    "y = np.array(df.rating_type.loc[df.rating > 0])\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data training and testing \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF score: 0.6829268292682927\n"
     ]
    }
   ],
   "source": [
    "# Random Forrest\n",
    "rf = RandomForestClassifier(n_estimators=101).fit(X_train, y_train)\n",
    "print(f'RF score: {rf.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD score: 0.8536585365853658\n"
     ]
    }
   ],
   "source": [
    "# SGD\n",
    "sgd = linear_model.SGDClassifier(loss='modified_huber').fit(X_train, y_train)\n",
    "print(f'SGD score: {sgd.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.5 s, sys: 545 ms, total: 21 s\n",
      "Wall time: 2min 6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estim...\n",
       "                                     subsample=None, tree_method=None,\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             iid='deprecated', n_jobs=4,\n",
       "             param_grid={'colsample_bytree': [0.3, 0.4, 0.5, 0.7],\n",
       "                         'eta': [0.05, 0.1, 0.15, 0.2, 0.25, 0.3],\n",
       "                         'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "                         'max_depth': [3, 4, 5, 6, 8, 10, 12, 15],\n",
       "                         'min_child_weight': [1, 3, 5, 7]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_log_loss', verbose=0)"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "xgb = XGBClassifier()\n",
    "parameters = {\n",
    "     \"eta\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n",
    "     \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
    "     \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
    "     \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    "     \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ]\n",
    "     }\n",
    "\n",
    "grid = GridSearchCV(xgb,\n",
    "                    parameters, n_jobs=4,\n",
    "                    scoring=\"neg_log_loss\",\n",
    "                    cv=3)\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'colsample_bytree': 0.5, 'eta': 0.05, 'gamma': 0.0, 'max_depth': 3, 'min_child_weight': 3}\n",
      "Best XGB score: 0.6585365853658537\n"
     ]
    }
   ],
   "source": [
    "best_xgb = grid.best_estimator_.fit(X_train, y_train)\n",
    "print(f'Best params: {grid.best_params_}')\n",
    "print(f'Best XGB score: {best_xgb.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier, Ensemble Acc: 0.8780487804878049\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Ensemble\n",
    "estimators = [('rf', rf1), ('sgd', sgd), ('xgb', best_xgb)]\n",
    "\n",
    "ensemble = VotingClassifier(estimators, voting='soft')\n",
    "ensemble.fit(X_train, y_train)\n",
    "print('Voting Classifier, Ensemble Acc: {}'.format(ensemble.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The ensemble method performed the best at 0.88 accuracy when taking cluster assignments and LDA probabilities as input. \n",
    "Save the model to a pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save ensemble model\n",
    "# pickle.dump(ensemble, open('models/rating_pred_ens_combined_model.pkl', 'wb'))\n",
    "\n",
    "# # Load ensemble model\n",
    "# with open('models/rating_pred_ens_combined_model.pkl','rb') as f: \n",
    "#     ensemble = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
