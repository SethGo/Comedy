{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Neural Network for Text Generation\n",
    "\n",
    "Here we will take a subset of the full transcript dataset and train a LSTM style Recurrent Network in order to generate new text based on the corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import seaborn as sns; sns.set(color_codes=True)\n",
    "import re \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the data from csv file that was created in get_transcripts.ipynb\n",
    "\n",
    "Take only the English transcripts since we will be training our model to produce text in English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>link</th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>transcript</th>\n",
       "      <th>language</th>\n",
       "      <th>runtime</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentences</th>\n",
       "      <th>words</th>\n",
       "      <th>sent_polarity</th>\n",
       "      <th>sent_subjectivity</th>\n",
       "      <th>word_polarity</th>\n",
       "      <th>word_subjectivity</th>\n",
       "      <th>words_per_sentence</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>f_words</th>\n",
       "      <th>s_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lee Mack: Live</td>\n",
       "      <td>May 7th, 2020</td>\n",
       "      <td>https://scrapsfromtheloft.com/2020/05/07/lee-m...</td>\n",
       "      <td>Lee Mack</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>TAKE ME OUT BY FRANZ FERDINAND PLAYING PRESENT...</td>\n",
       "      <td>en</td>\n",
       "      <td>68.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>['TAKE ME OUT BY FRANZ FERDINAND PLAYING PRESE...</td>\n",
       "      <td>['TAKE', 'ME', 'OUT', 'BY', 'FRANZ', 'FERDINAN...</td>\n",
       "      <td>[0.8 0.  0.  ... 0.  0.  0.7]</td>\n",
       "      <td>[0.9 0.  0.  ... 0.  0.  0.6]</td>\n",
       "      <td>[0.  0.  0.  ... 0.7 0.  0. ]</td>\n",
       "      <td>[0.  0.  0.  ... 0.6 0.  0. ]</td>\n",
       "      <td>8.848975</td>\n",
       "      <td>14238</td>\n",
       "      <td>1609</td>\n",
       "      <td>95</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T.J. Miller: No Real Reason</td>\n",
       "      <td>May 6th, 2020</td>\n",
       "      <td>https://scrapsfromtheloft.com/2020/05/06/t-j-m...</td>\n",
       "      <td>T.J. Miller</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>– I wish I didnt have to do this to perform, b...</td>\n",
       "      <td>en</td>\n",
       "      <td>67.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>['– I wish I didnt have to do this to perform,...</td>\n",
       "      <td>['–', 'I', 'wish', 'I', 'didnt', 'have', 'to',...</td>\n",
       "      <td>[ 1.00000000e-01 -7.00000000e-01 -7.00000000e-...</td>\n",
       "      <td>[1.         0.66666667 0.66666667 0.86666667 0...</td>\n",
       "      <td>[0.   0.   0.   ... 0.   0.35 0.  ]</td>\n",
       "      <td>[0.   0.   0.   ... 0.   0.65 0.  ]</td>\n",
       "      <td>11.701735</td>\n",
       "      <td>10789</td>\n",
       "      <td>922</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jerry Seinfeld: 23 Hours To Kill</td>\n",
       "      <td>May 6th, 2020</td>\n",
       "      <td>https://scrapsfromtheloft.com/2020/05/06/jerry...</td>\n",
       "      <td>Jerry Seinfeld</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Jerry Seinfelds new hourlong comedy special, J...</td>\n",
       "      <td>en</td>\n",
       "      <td>60.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>['Jerry Seinfelds new hourlong comedy special,...</td>\n",
       "      <td>['Jerry', 'Seinfelds', 'new', 'hourlong', 'com...</td>\n",
       "      <td>[ 0.2978355   0.          0.24285714  0.      ...</td>\n",
       "      <td>[0.47532468 0.         0.36785714 0.         0...</td>\n",
       "      <td>[0.         0.         0.13636364 ... 0.      ...</td>\n",
       "      <td>[0.         0.         0.45454545 ... 0.      ...</td>\n",
       "      <td>10.084926</td>\n",
       "      <td>9500</td>\n",
       "      <td>942</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bill Burr On The Late Show With David Letterma...</td>\n",
       "      <td>May 5th, 2020</td>\n",
       "      <td>https://scrapsfromtheloft.com/2020/05/05/bill-...</td>\n",
       "      <td>Bill Burr</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>Bill Burr performing on The Late Show with Dav...</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Bill Burr performing on The Late Show with D...</td>\n",
       "      <td>['Bill', 'Burr', 'performing', 'on', 'The', 'L...</td>\n",
       "      <td>[-0.3         0.375       0.          0.      ...</td>\n",
       "      <td>[0.6        0.63333333 0.         0.         0...</td>\n",
       "      <td>[0.  0.  0.  ... 0.2 0.2 0. ]</td>\n",
       "      <td>[0.  0.  0.  ... 0.3 0.2 0. ]</td>\n",
       "      <td>9.486726</td>\n",
       "      <td>1072</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sincerely Louis Ck</td>\n",
       "      <td>May 2nd, 2020</td>\n",
       "      <td>https://scrapsfromtheloft.com/2020/05/02/since...</td>\n",
       "      <td>Louis C.K.</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Great comedy is finally back. Louis C.K. is no...</td>\n",
       "      <td>en</td>\n",
       "      <td>60.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>['Great comedy is finally back.', 'Louis C.K.'...</td>\n",
       "      <td>['Great', 'comedy', 'is', 'finally', 'back', '...</td>\n",
       "      <td>[ 4.00000000e-01  0.00000000e+00  3.00000000e-...</td>\n",
       "      <td>[0.375      0.         0.9        0.5        0...</td>\n",
       "      <td>[0.8 0.  0.  ... 0.  0.  0. ]</td>\n",
       "      <td>[0.75 0.   0.   ... 0.   0.   0.  ]</td>\n",
       "      <td>11.088071</td>\n",
       "      <td>9946</td>\n",
       "      <td>897</td>\n",
       "      <td>93</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title    date_posted  \\\n",
       "0                                 Lee Mack: Live      May 7th, 2020   \n",
       "1                    T.J. Miller: No Real Reason      May 6th, 2020   \n",
       "2               Jerry Seinfeld: 23 Hours To Kill      May 6th, 2020   \n",
       "3  Bill Burr On The Late Show With David Letterma...  May 5th, 2020   \n",
       "4                                Sincerely Louis Ck   May 2nd, 2020   \n",
       "\n",
       "                                                link            name    year  \\\n",
       "0  https://scrapsfromtheloft.com/2020/05/07/lee-m...        Lee Mack  2007.0   \n",
       "1  https://scrapsfromtheloft.com/2020/05/06/t-j-m...     T.J. Miller  2011.0   \n",
       "2  https://scrapsfromtheloft.com/2020/05/06/jerry...  Jerry Seinfeld  2020.0   \n",
       "3  https://scrapsfromtheloft.com/2020/05/05/bill-...       Bill Burr  2010.0   \n",
       "4  https://scrapsfromtheloft.com/2020/05/02/since...      Louis C.K.  2020.0   \n",
       "\n",
       "                                          transcript language  runtime  \\\n",
       "0  TAKE ME OUT BY FRANZ FERDINAND PLAYING PRESENT...       en     68.0   \n",
       "1  – I wish I didnt have to do this to perform, b...       en     67.0   \n",
       "2  Jerry Seinfelds new hourlong comedy special, J...       en     60.0   \n",
       "3  Bill Burr performing on The Late Show with Dav...       en      NaN   \n",
       "4  Great comedy is finally back. Louis C.K. is no...       en     60.0   \n",
       "\n",
       "   rating                                          sentences  \\\n",
       "0     7.7  ['TAKE ME OUT BY FRANZ FERDINAND PLAYING PRESE...   \n",
       "1     7.1  ['– I wish I didnt have to do this to perform,...   \n",
       "2     6.7  ['Jerry Seinfelds new hourlong comedy special,...   \n",
       "3     NaN  ['Bill Burr performing on The Late Show with D...   \n",
       "4     8.5  ['Great comedy is finally back.', 'Louis C.K.'...   \n",
       "\n",
       "                                               words  \\\n",
       "0  ['TAKE', 'ME', 'OUT', 'BY', 'FRANZ', 'FERDINAN...   \n",
       "1  ['–', 'I', 'wish', 'I', 'didnt', 'have', 'to',...   \n",
       "2  ['Jerry', 'Seinfelds', 'new', 'hourlong', 'com...   \n",
       "3  ['Bill', 'Burr', 'performing', 'on', 'The', 'L...   \n",
       "4  ['Great', 'comedy', 'is', 'finally', 'back', '...   \n",
       "\n",
       "                                       sent_polarity  \\\n",
       "0                      [0.8 0.  0.  ... 0.  0.  0.7]   \n",
       "1  [ 1.00000000e-01 -7.00000000e-01 -7.00000000e-...   \n",
       "2  [ 0.2978355   0.          0.24285714  0.      ...   \n",
       "3  [-0.3         0.375       0.          0.      ...   \n",
       "4  [ 4.00000000e-01  0.00000000e+00  3.00000000e-...   \n",
       "\n",
       "                                   sent_subjectivity  \\\n",
       "0                      [0.9 0.  0.  ... 0.  0.  0.6]   \n",
       "1  [1.         0.66666667 0.66666667 0.86666667 0...   \n",
       "2  [0.47532468 0.         0.36785714 0.         0...   \n",
       "3  [0.6        0.63333333 0.         0.         0...   \n",
       "4  [0.375      0.         0.9        0.5        0...   \n",
       "\n",
       "                                       word_polarity  \\\n",
       "0                      [0.  0.  0.  ... 0.7 0.  0. ]   \n",
       "1                [0.   0.   0.   ... 0.   0.35 0.  ]   \n",
       "2  [0.         0.         0.13636364 ... 0.      ...   \n",
       "3                      [0.  0.  0.  ... 0.2 0.2 0. ]   \n",
       "4                      [0.8 0.  0.  ... 0.  0.  0. ]   \n",
       "\n",
       "                                   word_subjectivity  words_per_sentence  \\\n",
       "0                      [0.  0.  0.  ... 0.6 0.  0. ]            8.848975   \n",
       "1                [0.   0.   0.   ... 0.   0.65 0.  ]           11.701735   \n",
       "2  [0.         0.         0.45454545 ... 0.      ...           10.084926   \n",
       "3                      [0.  0.  0.  ... 0.3 0.2 0. ]            9.486726   \n",
       "4                [0.75 0.   0.   ... 0.   0.   0.  ]           11.088071   \n",
       "\n",
       "   word_count  sent_count  f_words  s_words  \n",
       "0       14238        1609       95        8  \n",
       "1       10789         922       11        2  \n",
       "2        9500         942        0        0  \n",
       "3        1072         113        0        0  \n",
       "4        9946         897       93       19  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data from csv\n",
    "df = pd.read_csv('stand-up-data-cleaned.csv')\n",
    "df = df.loc[df.language == 'en']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a variable 'text' that will serve as the corpus for our model\n",
    "This simply adds each transcript together into a single string. Instead of using the full corpus, we will only take 1/10th of it to save on memory and processing time and because this is just for fun. A more powerful generator could be made with the resources to process the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13166511"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ''\n",
    "for i in df.transcript:\n",
    "    text += (i + ' ')\n",
    "\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1316651"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shorten text by 1/10 to save processing time\n",
    "portion = int(len(text)/10)\n",
    "text = text[:portion]\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model: LSTM 256 -> LSTM 256 -> LSTM 256 -> Dense\n",
    "Much of this block is taken right from the Keras Docs. I have changed the network architecture, optimizer settings, and callback functions.\n",
    "\n",
    "Learning rate starts out at 0.001 and is allowed to run until it plateaus after about 30 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# Cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "# Turn 40-character chunks into vectors for the x. y is the next character in the original sequence\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "\n",
    "# Build the model: 3 layers deep LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, return_sequences=True, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "optimizer = Adam(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # Helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "\n",
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(150):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print('\\n')\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "# Checkpoint save on new best\n",
    "filepath = \"model_best.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=60,\n",
    "          callbacks=[print_callback, checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some mid-training gems generated by the model...\n",
    "- Epoch 10: \"I make you have a song for the porn before you think you're a good point, like, I'll give you an example. I was like, no.\"\n",
    "- Epoch 18: \"I make a bank that we're gonna be like, I don't know what the fuck I want. I don't know what the fuck I want to do it. And I don't know what the fuck I want.\"\n",
    "\n",
    "\n",
    "This is good! They sound like English, sort of. Not bad for character-level predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning is resumed with a smaller learning rate\n",
    "Now the Adam optimizer learning rate is set to 0.0001 for another 13 epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=0.0001) \n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "model.summary()\n",
    "\n",
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=60,\n",
    "          callbacks=[print_callback, checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Epoch 49: \"Its not what I meant, the thing the car the man didn't want to do it. I don't know what to do. It wasn't any good anyway.\"\n",
    "\n",
    "The model isn't quite making sense yet but it's interesting to see how it is attempting more complex sentences.\n",
    "\n",
    "### Learning is resumed with an even smaller learning rate\n",
    "Finally, the learning rate is set to 0.00001 for just 1 more epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=0.00001) \n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "model.summary()\n",
    "\n",
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=60,\n",
    "          callbacks=[print_callback, checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-load the model from 'model_best.h5' if needed, then produce results\n",
    "A great way to save your work is to use the keras callback ModelCheckpoint which can save the entire model so that you can come back later to continue training. Here I am using the model_best.h5 file to reload the model so that we can use it to generate our text for us. \n",
    "#### (I will only be using temperatures 0.5 and 1.0 since those seemed to produce the best results during training.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 40, 256)           324608    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 40, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 40, 256)           525312    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 40, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 60)                15420     \n",
      "=================================================================\n",
      "Total params: 1,390,652\n",
      "Trainable params: 1,390,652\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load the model from h5 file\n",
    "from keras.models import load_model\n",
    "\n",
    "filename = \"model_best.h5\"\n",
    "model = load_model(filename)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"You know what I mean? My mom used to be \"\n",
      "You know what I mean? My mom used to be like, When when you live at the room, like, Were gonna need to take a burned on here for a compliment for no reason for where I first come from the last thing I was like, What a guy fuck? Thats not the same hands on your crothing sling. You know what I mean? I had a baby. I was like, Oh, do you not be some shit? And then I had done that I love the jokes and I go to the received of the back of a sa\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"You know what I mean? My mom used to be \"\n",
      "You know what I mean? My mom used to be on a market shit about a ruin presidence of expecting by the first time. Just a Bohuwain, Hey, haya. She made you a drag. Its like, Thank you. a picture for expensive, saying, Noing news know, suck, would you go crazy? Shine of the trats that has the classrow lives of Aborting for your viswed into the under it. And Sorry, we did spit. I can really see you anything registry on a movie. I like to go\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Grab some random seed text and predict the next letters\n",
    "start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "for diversity in [0.5, 1.0]:\n",
    "    print('----- diversity:', diversity)\n",
    "\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    generated += sentence\n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    sys.stdout.write(generated)\n",
    "\n",
    "    for i in range(400):\n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds, diversity)\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "- In the end, the generated text looks like English with only a few spelling errors though it doesn't really make much sense. There are grammar and syntax errors everywhere but this is partially to be expected given that the source text is composed of transcripts from spoken stand-up comedy routines. Unfortunately, due to computational and time constraints, the full corpus was not used. It is possible that the results of this network, with 90% more training data, would be significantly different.\n",
    "\n",
    "- There is clearly a lot of work to be done before actually funny text could be created with this LSTM model... Unless you're into absurdist humor."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
